{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Untitled",
      "provenance": [],
      "authorship_tag": "ABX9TyNUbdYA4C8Tjd2rOs8txAhw",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/pg0/imagen-pytorch/blob/main/imagen-notebook.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5uZsVG6Rrjgk"
      },
      "outputs": [],
      "source": [
        "pip install imagen-pytorch"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from imagen_pytorch import Unet, Imagen"
      ],
      "metadata": {
        "id": "JDXno_yqiVui"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "torch.cuda.is_available()"
      ],
      "metadata": {
        "id": "aAsjc0k-i8F1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "torch.version.cuda"
      ],
      "metadata": {
        "id": "AB9H9qKpiO2m"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# unet for imagen\n",
        "\n",
        "unet1 = Unet(\n",
        "    dim = 32,\n",
        "    cond_dim = 512,\n",
        "    dim_mults = (1, 2, 4, 8),\n",
        "    num_resnet_blocks = 3,\n",
        "    layer_attns = (False, True, True, True),\n",
        "    layer_cross_attns = (False, True, True, True)\n",
        ")\n",
        "\n",
        "unet2 = Unet(\n",
        "    dim = 32,\n",
        "    cond_dim = 512,\n",
        "    dim_mults = (1, 2, 4, 8),\n",
        "    num_resnet_blocks = (2, 4, 8, 8),\n",
        "    layer_attns = (False, False, False, True),\n",
        "    layer_cross_attns = (False, False, False, True)\n",
        ")\n",
        "\n",
        "# imagen, which contains the unets above (base unet and super resoluting ones)\n",
        "\n",
        "imagen = Imagen(\n",
        "    unets = (unet1, unet2),\n",
        "    image_sizes = (64, 256),\n",
        "    timesteps = 1000,\n",
        "    cond_drop_prob = 0.1\n",
        ").cuda()\n",
        "\n",
        "# mock images (get a lot of this) and text encodings from large T5\n",
        "\n",
        "text_embeds = torch.randn(4, 256, 768).cuda()\n",
        "text_masks = torch.ones(4, 256).bool().cuda()\n",
        "images = torch.randn(4, 3, 256, 256).cuda()\n",
        "\n",
        "# feed images into imagen, training each unet in the cascade\n",
        "\n",
        "for i in (1, 2):\n",
        "    loss = imagen(images, text_embeds = text_embeds, text_masks = text_masks, unet_number = i)\n",
        "    loss.backward()"
      ],
      "metadata": {
        "id": "isbcpkI3htV1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "images = imagen.sample(texts = [\n",
        "    'a whale breaching from afar',\n",
        "    'young girl blowing out candles on her birthday cake',\n",
        "    'fireworks with blue and green sparkles'\n",
        "], cond_scale = 2.)\n",
        "\n",
        "images.shape # (3, 3, 256, 256)"
      ],
      "metadata": {
        "id": "erWQn9BwyflU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from imagen_pytorch import Unet, Imagen, ImagenTrainer\n",
        "\n",
        "# unet for imagen\n",
        "\n",
        "unet1 = Unet(\n",
        "    dim = 32,\n",
        "    cond_dim = 512,\n",
        "    dim_mults = (1, 2, 4, 8),\n",
        "    num_resnet_blocks = 3,\n",
        "    layer_attns = (False, True, True, True),\n",
        ")\n",
        "\n",
        "unet2 = Unet(\n",
        "    dim = 32,\n",
        "    cond_dim = 512,\n",
        "    dim_mults = (1, 2, 4, 8),\n",
        "    num_resnet_blocks = (2, 4, 8, 8),\n",
        "    layer_attns = (False, False, False, True),\n",
        "    layer_cross_attns = (False, False, False, True)\n",
        ")\n",
        "\n",
        "# imagen, which contains the unets above (base unet and super resoluting ones)\n",
        "\n",
        "imagen = Imagen(\n",
        "    unets = (unet1, unet2),\n",
        "    text_encoder_name = 't5-large',\n",
        "    image_sizes = (64, 256),\n",
        "    timesteps = 1000,\n",
        "    cond_drop_prob = 0.1\n",
        ").cuda()\n",
        "\n",
        "# wrap imagen with the trainer class\n",
        "\n",
        "trainer = ImagenTrainer(imagen)\n",
        "\n",
        "# mock images (get a lot of this) and text encodings from large T5\n",
        "\n",
        "text_embeds = torch.randn(64, 256, 1024).cuda()\n",
        "text_masks = torch.ones(64, 256).bool().cuda()\n",
        "images = torch.randn(64, 3, 256, 256).cuda()\n",
        "\n",
        "# feed images into imagen, training each unet in the cascade\n",
        "\n",
        "for i in (1, 2):\n",
        "    loss = trainer(\n",
        "        images,\n",
        "        text_embeds = text_embeds,\n",
        "        text_masks = text_masks,\n",
        "        unet_number = i,\n",
        "        max_batch_size = 4        # auto divide the batch of 64 up into batch size of 4 and accumulate gradients, so it all fits in memory\n",
        "    )\n",
        "\n",
        "    trainer.update(unet_number = i)\n",
        "\n",
        "# do the above for many many many many steps\n",
        "# now you can sample an image based on the text embeddings from the cascading ddpm\n",
        "\n",
        "images = trainer.sample(texts = [\n",
        "    'a puppy looking anxiously at a giant donut on the table',\n",
        "    'the milky way galaxy in the style of monet'\n",
        "], cond_scale = 3.)\n",
        "\n",
        "images.shape # (2, 3, 256, 256)"
      ],
      "metadata": {
        "id": "RPB4QnQkykNP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "fWXcJnwQ32S9"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}